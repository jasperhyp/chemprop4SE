{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5265dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ef99dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\data/mono.csv'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.join(os.curdir,\"data/mono.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30d6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "Molecule = Union[str, Chem.Mol]\n",
    "FeaturesGenerator = Callable[[Molecule], np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90ce39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "61c5fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv(\"./data/mono.csv\")\n",
    "b = dict([(a['smiles'][i], a.iloc[i].values[1:]) for i in range(len(a))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8e9e7476",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NC(CC1CC(I)C(OC2CC(I)C(O)C(I)C2)C(I)C1)C(=O)O'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5088/431849901.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NC(Cc1cc(I)c(Oc2cc(I)c(O)c(I)c2)c(I)c1)C(=O)O\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'NC(CC1CC(I)C(OC2CC(I)C(O)C(I)C2)C(I)C1)C(=O)O'"
     ]
    }
   ],
   "source": [
    "b[\"NC(Cc1cc(I)c(Oc2cc(I)c(O)c(I)c2)c(I)c1)C(=O)O\".upper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0be74f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4009849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6347it [00:00, 9920.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(path:=\"./data/test_random.csv\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    if target_columns is None:\n",
    "        target_columns = get_task_names(\n",
    "            path=path,\n",
    "            smiles_columns=smiles_columns,\n",
    "            target_columns=target_columns,\n",
    "            ignore_columns=ignore_columns,\n",
    "        )\n",
    "\n",
    "    all_smiles, all_targets, all_rows, all_features, all_phase_features, all_weights = [], [], [], [], [], []\n",
    "    for i, row in enumerate(tqdm(reader)):\n",
    "        smiles = [row[c] for c in ['smiles_1', 'smiles_2']]\n",
    "\n",
    "        targets = [float(row[column]) if row[column] not in ['','nan'] else None for column in target_columns]\n",
    "\n",
    "        # Check whether all targets are None and skip if so\n",
    "        if skip_none_targets and all(x is None for x in targets):\n",
    "            continue\n",
    "\n",
    "        all_smiles.append(smiles)\n",
    "        all_targets.append(targets)\n",
    "\n",
    "        if features_data is not None:\n",
    "            all_features.append(features_data[i])\n",
    "\n",
    "        if phase_features is not None:\n",
    "            all_phase_features.append(phase_features[i])\n",
    "\n",
    "        if data_weights is not None:\n",
    "            all_weights.append(data_weights[i])\n",
    "\n",
    "        if store_row:\n",
    "            all_rows.append(row)\n",
    "\n",
    "        if len(all_smiles) >= max_data_size:\n",
    "            break\n",
    "\n",
    "    atom_features = None\n",
    "    atom_descriptors = None\n",
    "    if args is not None and args.atom_descriptors is not None:\n",
    "        try:\n",
    "            descriptors = load_valid_atom_or_bond_features(atom_descriptors_path, [x[0] for x in all_smiles])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f'Failed to load or validate custom atomic descriptors or features: {e}')\n",
    "\n",
    "        if args.atom_descriptors == 'feature':\n",
    "            atom_features = descriptors\n",
    "        elif args.atom_descriptors == 'descriptor':\n",
    "            atom_descriptors = descriptors\n",
    "\n",
    "    bond_features = None\n",
    "    if args is not None and args.bond_features_path is not None:\n",
    "        try:\n",
    "            bond_features = load_valid_atom_or_bond_features(bond_features_path, [x[0] for x in all_smiles])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f'Failed to load or validate custom bond features: {e}')\n",
    "\n",
    "    data = MoleculeDataset([\n",
    "        MoleculeDatapoint(\n",
    "            smiles=smiles,\n",
    "            targets=targets,\n",
    "            row=all_rows[i] if store_row else None,\n",
    "            data_weight=all_weights[i] if data_weights is not None else 1.,\n",
    "            features_generator=features_generator,\n",
    "            features=all_features[i] if features_data is not None else None,\n",
    "            phase_features=all_phase_features[i] if phase_features is not None else None,\n",
    "            atom_features=atom_features[i] if atom_features is not None else None,\n",
    "            atom_descriptors=atom_descriptors[i] if atom_descriptors is not None else None,\n",
    "            bond_features=bond_features[i] if bond_features is not None else None,\n",
    "            overwrite_default_atom_features=args.overwrite_default_atom_features if args is not None else False,\n",
    "            overwrite_default_bond_features=args.overwrite_default_bond_features if args is not None else False\n",
    "        ) for i, (smiles, targets) in tqdm(enumerate(zip(all_smiles, all_targets)),\n",
    "                                           total=len(all_smiles))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad25351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C[C@@H]1C[C@H]2C3CCC4=CC(=O)C=C[C@@]4([C@]3([C@H](C[C@@]2([C@]1(C(=O)CCl)O)C)O)Cl)C'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"C[C@@H]1C[C@H]2C3CCC4=CC(=O)C=C[C@@]4([C@]3([C@H](C[C@@]2([C@]1(C(=O)CCl)O)C)O)Cl)C\"\n",
    "a.split(\">\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "544069fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.],\n",
       "         [11., 12., 13., 14., 15.]]),\n",
       " tensor([[ 5.,  4.,  3.,  2.,  1.],\n",
       "         [10.,  9.,  8.,  7.,  6.],\n",
       "         [15., 14., 13., 12., 11.]])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三对drugs\n",
    "mol_vecs1 = [torch.from_numpy(np.array([1,2,3,4,5])),\n",
    "            torch.from_numpy(np.array([6,7,8,9,10])),\n",
    "            torch.from_numpy(np.array([11,12,13,14,15]))]\n",
    "mol_vecs2 = [torch.from_numpy(np.array([5,4,3,2,1])),\n",
    "            torch.from_numpy(np.array([10,9,8,7,6])),\n",
    "            torch.from_numpy(np.array([15,14,13,12,11]))]\n",
    "\n",
    "encodings = [torch.stack(mol_vecs1, dim=0).float(), \n",
    "             torch.stack(mol_vecs2, dim=0).float()]\n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "357ce375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]]),\n",
       " tensor([[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_batch=[[[1,2],[3,4]],\n",
    "                [[5,6],[7,8]],\n",
    "                [[9,10],[11,12]]]\n",
    "test = [[features[i] for features in features_batch] for i in range(len(features_batch[0]))]\n",
    "\n",
    "features_batch = torch.from_numpy(np.stack(features_batch)).float()\n",
    "test = [torch.from_numpy(np.stack(test)[0]).float(),\n",
    "        torch.from_numpy(np.stack(test)[1]).float()]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4a54dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.,  2.,  3.,  4.,  5.,  1.,  2.],\n",
       "         [ 6.,  7.,  8.,  9., 10.,  5.,  6.],\n",
       "         [11., 12., 13., 14., 15.,  9., 10.]]),\n",
       " tensor([[ 5.,  4.,  3.,  2.,  1.,  3.,  4.],\n",
       "         [10.,  9.,  8.,  7.,  6.,  7.,  8.],\n",
       "         [15., 14., 13., 12., 11., 11., 12.]])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[torch.cat([encoding, batch], dim=1) for encoding, batch in zip(encodings, test)]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6331495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1.,   -2.,   -3.,   -2.,    1.,    1.,   -2.],\n",
       "        [ -44.,  -47.,  -48.,  -47.,  -44.,  -23.,  -34.],\n",
       "        [-139., -142., -143., -142., -139.,  -79.,  -98.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "output = reduce(lambda x, y: x+y-x*y, a)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
